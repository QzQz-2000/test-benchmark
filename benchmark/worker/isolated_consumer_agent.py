# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
ISOLATEDæ¨¡å¼Consumer Agent Worker - ç‹¬ç«‹è¿›ç¨‹å®ç°
æ¯ä¸ªConsumer Agentä½œä¸ºç‹¬ç«‹è¿›ç¨‹è¿è¡Œï¼Œå®Œå…¨éš”ç¦»
"""

import logging
import time


def isolated_consumer_agent(agent_id, topic, subscription_name, kafka_consumer_config,
                            stop_event, stats_queue, reset_flag, ready_queue, pause_event=None,
                            message_processing_delay_ms=0):
    """
    ç‹¬ç«‹Consumer Agentè¿›ç¨‹å·¥ä½œå‡½æ•° - ISOLATEDæ¨¡å¼

    :param agent_id: Agentå”¯ä¸€ID
    :param topic: è¦è®¢é˜…çš„ä¸»é¢˜
    :param subscription_name: Consumer group name
    :param kafka_consumer_config: Kafka Consumeré…ç½®å­—å…¸
    :param stop_event: multiprocessing.Event - åœæ­¢ä¿¡å·
    :param stats_queue: multiprocessing.Queue - ç»Ÿè®¡æ•°æ®é˜Ÿåˆ—
    :param reset_flag: multiprocessing.Value - é‡ç½®æ ‡å¿—ï¼ˆepochè®¡æ•°å™¨ï¼‰
    :param ready_queue: multiprocessing.Queue - å°±ç»ª/é”™è¯¯ä¿¡å·é˜Ÿåˆ—
    :param pause_event: multiprocessing.Event - æš‚åœä¿¡å·ï¼ˆç”¨äºbacklogæ¨¡å¼ï¼Œå¯é€‰ï¼‰
    :param message_processing_delay_ms: æ¶ˆæ¯å¤„ç†å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰ï¼Œç”¨äºæ¨¡æ‹Ÿæ…¢é€Ÿæ¶ˆè´¹è€…
    """
    # è®¾ç½®è¿›ç¨‹çº§æ—¥å¿—
    logger = logging.getLogger(f"consumer-agent-{agent_id}")
    logger.setLevel(logging.INFO)

    try:
        # é€šçŸ¥ä¸»è¿›ç¨‹ï¼šAgentæ­£åœ¨åˆå§‹åŒ–
        logger.info(f"Consumer Agent {agent_id} initializing...")

        # åœ¨è¿›ç¨‹å†…å¯¼å…¥ï¼ˆé¿å…åºåˆ—åŒ–é—®é¢˜ï¼‰
        from confluent_kafka import Consumer, KafkaError
        from hdrh.histogram import HdrHistogram

        logger.info(f"Consumer Agent {agent_id} starting (independent consumer process)")

        # 1. åˆ›å»ºç‹¬ç«‹çš„Kafka Consumer
        consumer_config = kafka_consumer_config.copy()
        consumer_config['group.id'] = subscription_name
        consumer_config['client.id'] = f'consumer-agent-{agent_id}'
        consumer = Consumer(consumer_config)

        # 1.5 å®šä¹‰ Rebalance Callbackï¼ˆç”¨äºç›‘æ§å’Œè°ƒè¯•ï¼‰
        rebalance_count = {'count': 0, 'last_time': time.time()}

        def on_assign(consumer, partitions):
            """å½“åˆ†åŒºè¢«åˆ†é…ç»™è¿™ä¸ª consumer æ—¶è°ƒç”¨"""
            rebalance_count['count'] += 1
            rebalance_count['last_time'] = time.time()
            partition_ids = [p.partition for p in partitions]
            logger.info(
                f"ğŸ”„ Consumer Agent {agent_id} REBALANCE #{rebalance_count['count']}: "
                f"Assigned {len(partitions)} partitions: {partition_ids}"
            )

        def on_revoke(consumer, partitions):
            """å½“åˆ†åŒºä»è¿™ä¸ª consumer æ’¤é”€æ—¶è°ƒç”¨"""
            partition_ids = [p.partition for p in partitions]
            logger.info(
                f"âš ï¸  Consumer Agent {agent_id} REBALANCE: "
                f"Revoked {len(partitions)} partitions: {partition_ids}"
            )

        def on_lost(consumer, partitions):
            """å½“åˆ†åŒºä¸¢å¤±æ—¶è°ƒç”¨ï¼ˆå¦‚è¶…æ—¶ï¼‰"""
            partition_ids = [p.partition for p in partitions]
            logger.warning(
                f"âŒ Consumer Agent {agent_id} PARTITION LOST: "
                f"Lost {len(partitions)} partitions: {partition_ids}"
            )

        # 2. è®¢é˜…topicï¼ˆå¸¦ rebalance callbackï¼‰
        consumer.subscribe([topic], on_assign=on_assign, on_revoke=on_revoke, on_lost=on_lost)
        logger.info(f"Consumer Agent {agent_id} subscribed to topic: {topic}, group: {subscription_name}")

        # æ˜¾ç¤ºæ¶ˆæ¯å¤„ç†å»¶è¿Ÿé…ç½®
        if message_processing_delay_ms > 0:
            logger.info(f"Consumer Agent {agent_id} configured with message processing delay: {message_processing_delay_ms} ms per message")
            logger.info(f"  â†’ This simulates slow consumer (delay is proportional to batch size)")

        # 3. æœ¬åœ°ç»Ÿè®¡å¯¹è±¡ï¼ˆè¿›ç¨‹å†…ç‹¬ç«‹ï¼‰
        # ä½¿ç”¨HdrHistogramæ›¿ä»£listï¼ˆä¸Javaç‰ˆæœ¬ä¸€è‡´ï¼‰
        class LocalStats:
            def __init__(self):
                self.messages_received = 0
                self.bytes_received = 0
                # End-to-endå»¶è¿Ÿhistogramï¼ˆèŒƒå›´æ›´å¤§ï¼š12å°æ—¶ï¼‰
                self.e2e_latency_histogram = HdrHistogram(1, 12 * 60 * 60 * 1_000, 5)

            def record_e2e_latency(self, latency_ms):
                """è®°å½•ç«¯åˆ°ç«¯å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰"""
                if 0 < latency_ms <= 12 * 60 * 60 * 1_000:
                    self.e2e_latency_histogram.record_value(int(latency_ms))

            def reset_histogram(self):
                """é‡ç½®histogram"""
                self.e2e_latency_histogram = HdrHistogram(1, 12 * 60 * 60 * 1_000, 5)

        local_stats = LocalStats()

        # å‘é€å°±ç»ªä¿¡å·ç»™ä¸»è¿›ç¨‹
        try:
            ready_queue.put({'agent_id': agent_id, 'status': 'ready', 'type': 'consumer'}, timeout=1.0)
            logger.info(f"Consumer Agent {agent_id} is ready")
        except Exception as e:
            logger.error(f"Consumer Agent {agent_id} failed to send ready signal: {e}")

        # 4. ç»Ÿè®¡æ±‡æŠ¥æ—¶é—´å’Œepochè·Ÿè¸ª
        last_stats_report = time.time()
        last_epoch_check = time.time()
        current_epoch = reset_flag.value if reset_flag else 0

        # 5. Consumerä¸»å¾ªç¯
        message_count = 0  # æ€»æ¶ˆæ¯è®¡æ•°ï¼ˆç”¨äºæ—¥å¿—ï¼‰

        while not stop_event.is_set():
            try:
                # 5.0 æ£€æŸ¥æ˜¯å¦æš‚åœï¼ˆbacklogæ¨¡å¼ï¼‰
                if pause_event and pause_event.is_set():
                    # ğŸ›‘ æš‚åœæ¨¡å¼ï¼šä¸å¤„ç†æ¶ˆæ¯ï¼Œä½†è°ƒç”¨ poll(0) ç»´æŒå¿ƒè·³
                    # è¿™æ · consumer ä»ç„¶åœ¨ group ä¸­ï¼Œä¸ä¼šè§¦å‘ rebalance
                    _ = consumer.consume(num_messages=1, timeout=0.1)
                    time.sleep(0.1)  # æš‚åœæ—¶é™ä½ CPU ä½¿ç”¨
                    continue

                # 5.1 æ‰¹é‡Pollæ¶ˆæ¯ï¼ˆä¸€æ¬¡æœ€å¤š100æ¡ï¼Œtimeout 100msï¼‰
                # âœ… ä¼˜åŒ–ï¼šå‡å°‘ timeout ä» 1ç§’åˆ° 100msï¼Œé™ä½å»¶è¿Ÿ
                messages = consumer.consume(num_messages=100, timeout=0.1)

                if not messages:
                    # æ²¡æœ‰æ¶ˆæ¯ï¼Œç»§ç»­
                    pass
                else:
                    # æ‰¹é‡å¤„ç†æ¶ˆæ¯
                    for msg in messages:
                        if msg.error():
                            # é”™è¯¯å¤„ç†
                            if msg.error().code() == KafkaError._PARTITION_EOF:
                                # åˆ†åŒºæœ«å°¾ï¼Œæ­£å¸¸æƒ…å†µ
                                logger.debug(f"Consumer Agent {agent_id} reached end of partition {msg.partition()}")
                            else:
                                logger.error(f"Consumer Agent {agent_id} error: {msg.error()}")
                            continue

                        # æˆåŠŸæ¥æ”¶æ¶ˆæ¯
                        message_count += 1
                        local_stats.messages_received += 1

                        # ä» payload ä¸­æå–æ—¶é—´æˆ³ï¼ˆå‰8å­—èŠ‚ï¼‰
                        payload = msg.value()
                        if payload and len(payload) >= 8:
                            import struct
                            # è§£æå‰8å­—èŠ‚çš„æ—¶é—´æˆ³ï¼ˆå¤§ç«¯åºï¼‰
                            publish_timestamp_ms = struct.unpack('>Q', payload[:8])[0]
                            receive_timestamp_ms = int(time.time() * 1000)
                            e2e_latency_ms = receive_timestamp_ms - publish_timestamp_ms

                            # ç»Ÿè®¡å®Œæ•´æ¶ˆæ¯å¤§å°ï¼ˆåŒ…å«æ—¶é—´æˆ³ï¼‰ï¼Œä¸Producerä¿æŒä¸€è‡´
                            # è¿™æ ·Producerå‘é€çš„bytes_sentå’ŒConsumeræ¥æ”¶çš„bytes_receivedèƒ½å¯¹åº”ä¸Š
                            local_stats.bytes_received += len(payload)

                            if message_count <= 5:
                                logger.info(f"Consumer Agent {agent_id} msg {message_count}: E2E latency={e2e_latency_ms} ms (pub={publish_timestamp_ms}, recv={receive_timestamp_ms})")

                            # è®°å½•åˆ°histogramï¼ˆä¸Javaç‰ˆæœ¬ä¸€è‡´ï¼‰
                            local_stats.record_e2e_latency(e2e_latency_ms)
                        else:
                            # Payload å¤ªå°æˆ–ä¸ºç©ºï¼Œæ— æ³•æå–æ—¶é—´æˆ³
                            local_stats.bytes_received += len(payload) if payload else 0
                            if message_count <= 5:
                                logger.warning(f"Consumer Agent {agent_id} msg {message_count}: Payload too small ({len(payload) if payload else 0} bytes), cannot extract timestamp")

                    # 5.1.5 åº”ç”¨æ¶ˆæ¯å¤„ç†å»¶è¿Ÿï¼ˆæ¨¡æ‹Ÿæ…¢é€Ÿæ¶ˆè´¹è€…ï¼‰
                    # æ–¹æ¡ˆ Cï¼šæ‰¹é‡å¤„ç†åæŒ‰æ¶ˆæ¯æ•°é‡æ¯”ä¾‹å»¶è¿Ÿ
                    if message_processing_delay_ms > 0 and messages:
                        delay_seconds = len(messages) * (message_processing_delay_ms / 1000.0)
                        time.sleep(delay_seconds)
                        if message_count <= 105:  # å‰å‡ æ‰¹æ˜¾ç¤ºæ—¥å¿—
                            logger.debug(f"Consumer Agent {agent_id} applied processing delay: {delay_seconds:.3f}s for {len(messages)} messages")

                # 5.2 æ£€æŸ¥epoché‡ç½®ï¼ˆæ¯ 0.2ç§’æ£€æŸ¥ä¸€æ¬¡ï¼Œæé«˜å“åº”é€Ÿåº¦ï¼‰
                now = time.time()
                if now - last_epoch_check > 0.2:
                    if reset_flag:
                        new_epoch = reset_flag.value
                        if new_epoch > current_epoch:
                            logger.info(f"Consumer Agent {agent_id} detected stats reset: epoch {current_epoch} -> {new_epoch}")

                            # ğŸ”§ FIX Bug #3: å…ˆå‘é€æ—§ epoch çš„æœ€ç»ˆç»Ÿè®¡ï¼Œå†åˆ‡æ¢åˆ°æ–° epoch
                            try:
                                final_old_epoch_stats = {
                                    'agent_id': agent_id,
                                    'type': 'consumer',
                                    'messages_received': local_stats.messages_received,
                                    'bytes_received': local_stats.bytes_received,
                                    'timestamp': now,
                                    'epoch': current_epoch,
                                    'final_epoch': True,  # æ ‡è®°ä¸º epoch çš„æœ€åä¸€æ‰¹æ•°æ®
                                    'e2e_latency_histogram_encoded': local_stats.e2e_latency_histogram.encode(),
                                }
                                stats_queue.put(final_old_epoch_stats, timeout=1.0)
                                logger.info(f"Consumer Agent {agent_id} sent final stats for epoch {current_epoch}")
                            except Exception as e:
                                logger.warning(f"Consumer Agent {agent_id} failed to send final epoch {current_epoch} stats: {e}")

                            # åˆ‡æ¢åˆ°æ–° epoch
                            current_epoch = new_epoch

                            # é‡ç½®æœ¬åœ°ç»Ÿè®¡
                            local_stats.messages_received = 0
                            local_stats.bytes_received = 0
                            local_stats.reset_histogram()  # Epoch åˆ‡æ¢æ—¶é‡ç½® histogram

                            # ç«‹å³å‘é€æ–°epochç»Ÿè®¡ï¼Œæ— éœ€ç­‰å¾…ä¸‹ä¸€ä¸ªæŠ¥å‘Šå‘¨æœŸ
                            last_stats_report = now - 1.0  # å¼ºåˆ¶ä¸‹æ¬¡å¾ªç¯ç«‹å³å‘é€

                    last_epoch_check = now

                # 5.3 å®šæœŸæ±‡æŠ¥ç»Ÿè®¡ï¼ˆæ¯ç§’ä¸€æ¬¡ï¼‰
                if now - last_stats_report >= 1.0:
                    try:
                        # ğŸ”§ FIX Bug #1: åªåœ¨æˆåŠŸå‘é€åæ‰é‡ç½®è®¡æ•°å™¨ï¼Œé¿å…æ•°æ®ä¸¢å¤±
                        # å‘é€histogramç¼–ç æ•°æ®ï¼ˆä¸Javaç‰ˆæœ¬ä¸€è‡´ï¼‰
                        # æ³¨æ„ï¼šhistogram ä¸é‡ç½®ï¼ˆç´¯ç§¯ç»Ÿè®¡ï¼‰ï¼Œè®¡æ•°å™¨æ¯æ¬¡é‡ç½®
                        stats_dict = {
                            'agent_id': agent_id,
                            'type': 'consumer',
                            'messages_received': local_stats.messages_received,
                            'bytes_received': local_stats.bytes_received,
                            'timestamp': now,
                            'epoch': current_epoch,
                            # å‘é€ç¼–ç åçš„histogramï¼ˆç´¯ç§¯æ•°æ®ï¼Œä¸é‡ç½®ï¼‰
                            'e2e_latency_histogram_encoded': local_stats.e2e_latency_histogram.encode(),
                        }

                        # ä½¿ç”¨å¸¦è¶…æ—¶çš„putï¼Œé¿å…é˜Ÿåˆ—æ»¡æ—¶é˜»å¡
                        queue_put_success = False
                        try:
                            stats_queue.put(stats_dict, timeout=0.1)
                            queue_put_success = True
                        except:
                            logger.warning(f"Consumer Agent {agent_id} stats queue full, histogram preserved but counters will be lost")

                        # âœ… è®¡æ•°å™¨æ€»æ˜¯é‡ç½®ï¼ˆé¿å…é‡å¤è®¡æ•°ï¼‰
                        # è®¡æ•°å™¨æ˜¯å¢é‡æ•°æ®ï¼Œä¸èƒ½ç´¯åŠ ï¼›histogram æ˜¯ç´¯ç§¯æ•°æ®ï¼Œå¯ä»¥ä¿ç•™
                        local_stats.messages_received = 0
                        local_stats.bytes_received = 0

                    except Exception as e:
                        logger.error(f"Consumer Agent {agent_id} failed to send stats: {e}", exc_info=True)
                        # âœ… å¼‚å¸¸æ—¶ä¹Ÿè¦é‡ç½®è®¡æ•°å™¨ï¼ˆé¿å…é‡å¤è®¡æ•°ï¼‰
                        local_stats.messages_received = 0
                        local_stats.bytes_received = 0

                    last_stats_report = now

            except KeyboardInterrupt:
                logger.info(f"Consumer Agent {agent_id} received keyboard interrupt, stopping...")
                break
            except Exception as e:
                logger.error(f"Consumer Agent {agent_id} error in poll loop: {e}", exc_info=True)
                time.sleep(0.1)

        logger.info(f"Consumer Agent {agent_id} stopping gracefully (received {message_count} messages total)")

    except Exception as e:
        logger.error(f"Consumer Agent {agent_id} fatal error: {e}", exc_info=True)
        # å‘é€é”™è¯¯ä¿¡å·ç»™ä¸»è¿›ç¨‹
        try:
            ready_queue.put({'agent_id': agent_id, 'status': 'error', 'type': 'consumer', 'error': str(e)}, timeout=0.5)
        except:
            pass

    finally:
        # 6. æ¸…ç†èµ„æº
        try:
            consumer.close()
            logger.info(f"Consumer Agent {agent_id} closed consumer")
        except Exception as e:
            logger.error(f"Consumer Agent {agent_id} error closing consumer: {e}")

        # 7. å‘é€æœ€ç»ˆç»Ÿè®¡åˆ°Queue
        try:
            final_stats = {
                'agent_id': agent_id,
                'type': 'consumer',
                'final': True,
                'total_messages': message_count
            }
            stats_queue.put(final_stats, timeout=1.0)
            logger.info(f"Consumer Agent {agent_id} sent final stats to queue")
        except Exception as e:
            logger.error(f"Consumer Agent {agent_id} error sending final stats: {e}")

        logger.info(f"Consumer Agent {agent_id} terminated")
