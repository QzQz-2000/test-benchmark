# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
ISOLATEDæ¨¡å¼Agent Worker - ç‹¬ç«‹è¿›ç¨‹å®ç°
æ¯ä¸ªAgentä»£è¡¨ä¸€ä¸ªç‹¬ç«‹çš„æ•°å­—å­ªç”Ÿå®ä½“ï¼ˆä¼ æ„Ÿå™¨ã€è®¾å¤‡ã€è½¦è¾†ç­‰ï¼‰
"""

import logging
import time
import random


def isolated_agent_worker(agent_id, topic, kafka_producer_config, kafka_consumer_config,
                         work_assignment, stop_event, stats_queue, shared_rate, reset_flag, ready_queue,
                         start_producing_event=None):
    """
    ç‹¬ç«‹Agentè¿›ç¨‹å·¥ä½œå‡½æ•° - ISOLATEDæ¨¡å¼
    æ¨¡æ‹Ÿä¸€ä¸ªå®Œå…¨ç‹¬ç«‹çš„æ•°å­—å­ªç”Ÿå®ä½“

    :param agent_id: Agentå”¯ä¸€ID
    :param topic: è¦å‘é€/è®¢é˜…çš„ä¸»é¢˜
    :param kafka_producer_config: Kafka Produceré…ç½®å­—å…¸
    :param kafka_consumer_config: Kafka Consumeré…ç½®å­—å…¸ï¼ˆå¯é€‰ï¼‰
    :param work_assignment: ProducerWorkAssignmentå¯¹è±¡ï¼ˆåŒ…å«payloadã€rateç­‰ï¼‰
    :param stop_event: multiprocessing.Event - åœæ­¢ä¿¡å·
    :param stats_queue: multiprocessing.Queue - ç»Ÿè®¡æ•°æ®é˜Ÿåˆ—
    :param shared_rate: multiprocessing.Value - å…±äº«é€Ÿç‡ï¼ˆæ”¯æŒåŠ¨æ€è°ƒæ•´ï¼‰
    :param reset_flag: multiprocessing.Value - é‡ç½®æ ‡å¿—ï¼ˆepochè®¡æ•°å™¨ï¼‰
    :param ready_queue: multiprocessing.Queue - å°±ç»ª/é”™è¯¯ä¿¡å·é˜Ÿåˆ—
    """
    # è®¾ç½®è¿›ç¨‹çº§æ—¥å¿—
    logger = logging.getLogger(f"agent-{agent_id}")
    logger.setLevel(logging.INFO)

    try:
        # é€šçŸ¥ä¸»è¿›ç¨‹ï¼šAgentæ­£åœ¨åˆå§‹åŒ–
        logger.info(f"Agent {agent_id} initializing...")
        # åœ¨è¿›ç¨‹å†…å¯¼å…¥ï¼ˆé¿å…åºåˆ—åŒ–é—®é¢˜ï¼‰
        from confluent_kafka import Producer, Consumer
        from hdrh.histogram import HdrHistogram
        from benchmark.utils.uniform_rate_limiter import UniformRateLimiter

        logger.info(f"Agent {agent_id} starting (simulating independent digital twin entity)")

        # 1. åˆ›å»ºç‹¬ç«‹çš„Kafka Producerï¼ˆæ¯ä¸ªAgentè‡ªå·±çš„è¿æ¥ï¼‰
        producer_config = kafka_producer_config.copy()
        producer_config['client.id'] = f'agent-{agent_id}-producer'
        producer = Producer(producer_config)

        # 2. æœ¬åœ°ç»Ÿè®¡å¯¹è±¡ï¼ˆè¿›ç¨‹å†…ç‹¬ç«‹ï¼‰
        # ä½¿ç”¨HdrHistogramæ›¿ä»£listï¼Œå†…å­˜å›ºå®šä¸”ç²¾ç¡®ï¼ˆä¸Javaç‰ˆæœ¬ä¸€è‡´ï¼‰
        class LocalStats:
            def __init__(self):
                self.messages_sent = 0
                self.bytes_sent = 0
                self.errors = 0
                # ä½¿ç”¨HdrHistogramè®°å½•å»¶è¿Ÿï¼ˆä¸Javaç‰ˆæœ¬ä¸€è‡´ï¼‰
                # å»¶è¿ŸèŒƒå›´: 1ms - 60ç§’ï¼Œç²¾åº¦5ä½æœ‰æ•ˆæ•°å­—
                self.pub_latency_histogram = HdrHistogram(1, 60 * 1_000, 5)
                self.pub_delay_histogram = HdrHistogram(1, 60 * 1_000, 5)

            def record_pub_latency(self, latency_ms):
                """è®°å½•å‘å¸ƒå»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰"""
                if 0 < latency_ms <= 60 * 1_000:
                    self.pub_latency_histogram.record_value(int(latency_ms))

            def record_pub_delay(self, delay_ms):
                """è®°å½•å‘å¸ƒå»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰"""
                if 0 <= delay_ms <= 60 * 1_000:
                    self.pub_delay_histogram.record_value(int(delay_ms))

            def reset_histograms(self):
                """é‡ç½®histogram"""
                self.pub_latency_histogram = HdrHistogram(1, 60 * 1_000, 5)
                self.pub_delay_histogram = HdrHistogram(1, 60 * 1_000, 5)

        local_stats = LocalStats()

        # 3. è·å–payload
        if not work_assignment or not work_assignment.payload_data:
            logger.error(f"Agent {agent_id}: No payload data provided")
            return

        # åŸå§‹ payloadï¼ˆä¸åŒ…å«æ—¶é—´æˆ³ï¼‰
        base_payload = work_assignment.payload_data[0] if work_assignment.payload_data else bytes(1024)

        # 4. é€Ÿç‡é™åˆ¶å™¨
        current_rate = shared_rate.value if shared_rate else work_assignment.publish_rate
        rate_limiter = UniformRateLimiter(current_rate)

        logger.info(f"Agent {agent_id} configured: topic={topic}, base_payload_size={len(base_payload)}, rate={current_rate} msg/s")

        # å‘é€å°±ç»ªä¿¡å·ç»™ä¸»è¿›ç¨‹
        try:
            ready_queue.put({'agent_id': agent_id, 'status': 'ready', 'type': 'producer'}, timeout=1.0)
            logger.info(f"Agent {agent_id} is ready")
        except Exception as e:
            logger.error(f"Agent {agent_id} failed to send ready signal: {e}")

        # âœ… ç­‰å¾…å¼€å§‹ç”Ÿäº§ä¿¡å·ï¼ˆè®© Consumer Group å…ˆç¨³å®šï¼‰
        if start_producing_event:
            logger.info(f"Agent {agent_id} waiting for start_producing signal...")
            start_producing_event.wait()  # é˜»å¡ç›´åˆ°ä¸»è¿›ç¨‹è®¾ç½®æ­¤äº‹ä»¶
            logger.info(f"Agent {agent_id} received start signal, beginning to produce messages")

        # 5. ç»Ÿè®¡æ±‡æŠ¥æ—¶é—´å’Œepochè·Ÿè¸ª
        last_rate_check = time.time()
        last_stats_report = time.time()
        current_epoch = reset_flag.value if reset_flag else 0

        # 6. Agentä¸»å¾ªç¯
        message_count = 0
        loop_times = []  # Track loop timing for debugging

        while not stop_event.is_set():
            try:
                # âœ… æ£€æŸ¥æ˜¯å¦åº”è¯¥æš‚åœï¼ˆç”¨äº backlog æ¨¡å¼ï¼Œä¸ç”¨äº warmupï¼‰
                if start_producing_event and not start_producing_event.is_set():
                    # Producer è¢«æš‚åœï¼Œç­‰å¾…é‡æ–°å¼€å§‹ä¿¡å·
                    producer.poll(0)  # ç»§ç»­å¤„ç† callbacks
                    time.sleep(0.01)  # çŸ­æš‚sleepé¿å…CPUç©ºè½¬
                    continue

                loop_iter_start = time.perf_counter() if message_count < 50 else None

                # 6.1 æ£€æŸ¥é€Ÿç‡è°ƒæ•´å’Œepoché‡ç½®ï¼ˆæ¯100msæ£€æŸ¥ä¸€æ¬¡ï¼‰
                now = time.time()
                if now - last_rate_check > 0.1:
                    # æ£€æŸ¥é€Ÿç‡è°ƒæ•´
                    if shared_rate:
                        new_rate = shared_rate.value
                        if abs(new_rate - current_rate) > 0.01:
                            current_rate = new_rate
                            rate_limiter = UniformRateLimiter(current_rate)
                            logger.info(f"Agent {agent_id} rate adjusted to {current_rate:.2f} msg/s")

                    # æ£€æŸ¥epoché‡ç½®
                    if reset_flag:
                        new_epoch = reset_flag.value
                        if new_epoch > current_epoch:
                            logger.info(f"Agent {agent_id} detected stats reset: epoch {current_epoch} -> {new_epoch}, resetting local stats")

                            # ğŸ”§ FIX Bug #3: å…ˆå‘é€æ—§ epoch çš„æœ€ç»ˆç»Ÿè®¡ï¼Œå†åˆ‡æ¢åˆ°æ–° epoch
                            # è¿™æ ·å¯ä»¥é¿å…æœ€åä¸€æ‰¹ histogram æ•°æ®ä¸¢å¤±
                            try:
                                final_old_epoch_stats = {
                                    'agent_id': agent_id,
                                    'type': 'producer',
                                    'messages_sent': local_stats.messages_sent,
                                    'bytes_sent': local_stats.bytes_sent,
                                    'errors': local_stats.errors,
                                    'timestamp': now,
                                    'epoch': current_epoch,
                                    'final_epoch': True,  # æ ‡è®°ä¸º epoch çš„æœ€åä¸€æ‰¹æ•°æ®
                                    'pub_latency_histogram_encoded': local_stats.pub_latency_histogram.encode(),
                                    'pub_delay_histogram_encoded': local_stats.pub_delay_histogram.encode(),
                                }
                                stats_queue.put(final_old_epoch_stats, timeout=1.0)
                                logger.info(f"Agent {agent_id} sent final stats for epoch {current_epoch}")
                            except Exception as e:
                                logger.warning(f"Agent {agent_id} failed to send final epoch {current_epoch} stats: {e}")

                            # åˆ‡æ¢åˆ°æ–° epoch
                            current_epoch = new_epoch

                            # é‡ç½®æœ¬åœ°ç»Ÿè®¡ï¼ˆhistogram åœ¨ epoch åˆ‡æ¢æ—¶éœ€è¦é‡ç½®ï¼‰
                            local_stats.messages_sent = 0
                            local_stats.bytes_sent = 0
                            local_stats.errors = 0
                            local_stats.reset_histograms()  # Epoch åˆ‡æ¢æ—¶é‡ç½® histogram æ˜¯åˆç†çš„

                            # ä¸é‡æ–°åˆ›å»ºRateLimiterï¼Œä¿æŒé€Ÿç‡è¿ç»­æ€§ï¼ˆä¸Javaç‰ˆæœ¬ä¸€è‡´ï¼‰
                            # ç«‹å³å‘é€æ–°epochç»Ÿè®¡ï¼Œæ— éœ€ç­‰å¾…ä¸‹ä¸€ä¸ªæŠ¥å‘Šå‘¨æœŸ
                            last_stats_report = now - 1.0  # å¼ºåˆ¶ä¸‹æ¬¡å¾ªç¯ç«‹å³å‘é€

                    last_rate_check = now

                # 6.2 é€Ÿç‡é™åˆ¶ - è·å–é¢„æœŸå‘é€æ—¶é—´
                intended_send_time_ns = rate_limiter.acquire()

                # 6.3 ç­‰å¾…å¹¶å¤„ç†callbacksï¼ˆé¿å…callbackå †ç§¯ï¼ŒåŒæ—¶ä¿æŒç²¾ç¡®çš„å‘é€æ—¶é—´ï¼‰
                # ç­–ç•¥ï¼šåœ¨ç­‰å¾…æœŸé—´æŒç»­å¤„ç†callbacksï¼ˆéé˜»å¡ï¼‰ï¼Œç²¾ç¡®æ§åˆ¶å‘é€æ—¶é—´
                remaining_ns = intended_send_time_ns - time.perf_counter_ns()

                # åœ¨ç­‰å¾…æœŸé—´æŒç»­poll(0)å¤„ç†callbacksï¼Œç›´åˆ°æ¥è¿‘å‘é€æ—¶é—´
                while remaining_ns > 100_000:  # å‰©ä½™è¶…è¿‡100å¾®ç§’
                    producer.poll(0)  # éé˜»å¡pollï¼Œç«‹å³è¿”å›

                    # é‡æ–°è®¡ç®—å‰©ä½™æ—¶é—´
                    remaining_ns = intended_send_time_ns - time.perf_counter_ns()

                    # å¦‚æœè¿˜æœ‰è¾ƒå¤šå‰©ä½™æ—¶é—´ï¼ŒçŸ­æš‚sleepé¿å…CPUç©ºè½¬
                    if remaining_ns > 500_000:  # å‰©ä½™è¶…è¿‡500å¾®ç§’
                        time.sleep(0.0001)  # sleep 100å¾®ç§’

                # æœ€åç²¾ç¡®ç­‰å¾…åˆ°intended_send_time
                remaining_ns = intended_send_time_ns - time.perf_counter_ns()
                if remaining_ns > 0:
                    time.sleep(remaining_ns / 1_000_000_000)

                send_time_ns = time.perf_counter_ns()

                # 6.4 é€‰æ‹©keyï¼ˆæ ¹æ®åˆ†å¸ƒç­–ç•¥ï¼‰
                key = None
                if work_assignment.key_distributor_type and hasattr(work_assignment.key_distributor_type, 'name'):
                    if work_assignment.key_distributor_type.name == 'RANDOM_NANO':
                        key = str(random.randint(0, 1000000))
                    elif work_assignment.key_distributor_type.name == 'KEY_ROUND_ROBIN':
                        key = str(agent_id)
                    # NO_KEY: keyä¿æŒNone

                # 6.5 åœ¨ payload å‰é¢åŠ ä¸Šæ—¶é—´æˆ³ï¼ˆ8å­—èŠ‚ï¼Œå¤§ç«¯åºï¼‰
                import struct
                send_timestamp_ms = int(time.time() * 1000)
                payload_with_timestamp = struct.pack('>Q', send_timestamp_ms) + base_payload

                # 6.6 å‘é€æ¶ˆæ¯ï¼ˆå¼‚æ­¥ï¼‰+ è½»é‡çº§å›è°ƒç»Ÿè®¡
                def delivery_callback(err, msg, intended=intended_send_time_ns, sent=send_time_ns):
                    if err:
                        local_stats.errors += 1
                    else:
                        ack_time_ns = time.perf_counter_ns()
                        local_stats.messages_sent += 1
                        # ç»Ÿè®¡å®é™…å‘é€çš„å­—èŠ‚æ•°ï¼ˆåŒ…å«8å­—èŠ‚æ—¶é—´æˆ³ï¼‰ï¼Œä¸Javaç‰ˆæœ¬ä¸€è‡´
                        # Javaç‰ˆæœ¬ç»Ÿè®¡çš„æ˜¯å®Œæ•´çš„æ¶ˆæ¯å¤§å°ï¼ˆåŒ…å«æ‰€æœ‰headerå’Œtimestampï¼‰
                        local_stats.bytes_sent += len(payload_with_timestamp)

                        # è®¡ç®—å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰- ä¸Javaç‰ˆæœ¬ä¸€è‡´
                        publish_latency_ms = (ack_time_ns - sent) // 1_000_000
                        publish_delay_ms = (sent - intended) // 1_000_000

                        # è®°å½•åˆ°HdrHistogramï¼ˆä¸Javaç‰ˆæœ¬ä¸€è‡´ï¼Œæ— æ ·æœ¬æ•°é™åˆ¶ï¼‰
                        local_stats.record_pub_latency(publish_latency_ms)
                        local_stats.record_pub_delay(publish_delay_ms)

                producer.produce(
                    topic=topic,
                    key=key.encode('utf-8') if key else None,
                    value=payload_with_timestamp,
                    callback=delivery_callback
                )

                message_count += 1

                # 6.7 å‘é€åå†æ¬¡poll(0)ç¡®ä¿æ–°æ¶ˆæ¯å¼€å§‹å¤„ç†
                # å‰é¢çš„pollå¾ªç¯å·²ç»å¤„ç†äº†å¤§éƒ¨åˆ†callbacksï¼Œè¿™é‡Œåªæ˜¯è§¦å‘æ–°æ¶ˆæ¯çš„å¤„ç†
                producer.poll(0)

                # Log timing for first 50 iterations
                if loop_iter_start is not None:
                    loop_time = (time.perf_counter() - loop_iter_start) * 1000  # ms
                    logger.info(f"Agent {agent_id} iteration {message_count}: {loop_time:.2f} ms")

                # 6.6 å®šæœŸæ±‡æŠ¥ç»Ÿè®¡ï¼ˆæ¯ç§’ä¸€æ¬¡ï¼‰
                if now - last_stats_report >= 1.0:
                    try:
                        # ğŸ”§ FIX Bug #1: åªåœ¨æˆåŠŸå‘é€åæ‰é‡ç½® histogramï¼Œé¿å…æ•°æ®ä¸¢å¤±
                        # ç¼–ç åçš„histograméå¸¸ç´§å‡‘ï¼ˆé€šå¸¸å‡ KBï¼‰
                        stats_dict = {
                            'agent_id': agent_id,
                            'type': 'producer',
                            'messages_sent': local_stats.messages_sent,
                            'bytes_sent': local_stats.bytes_sent,
                            'errors': local_stats.errors,
                            'timestamp': now,
                            'epoch': current_epoch,
                            # å‘é€ç¼–ç åçš„histogramï¼ˆç´§å‡‘ä¸”å®Œæ•´ï¼‰
                            'pub_latency_histogram_encoded': local_stats.pub_latency_histogram.encode(),
                            'pub_delay_histogram_encoded': local_stats.pub_delay_histogram.encode(),
                        }
                        # ä½¿ç”¨å¸¦è¶…æ—¶çš„putï¼Œé¿å…é˜Ÿåˆ—æ»¡æ—¶é˜»å¡
                        queue_put_success = False
                        try:
                            stats_queue.put(stats_dict, timeout=0.1)
                            queue_put_success = True
                        except:
                            # é˜Ÿåˆ—æ»¡ï¼Œè®°å½•è­¦å‘Šä½†ä¿ç•™ histogram æ•°æ®åˆ°ä¸‹æ¬¡å‘é€
                            logger.warning(f"Agent {agent_id} stats queue full, preserving histogram for next period (sent={local_stats.messages_sent})")

                        # âœ… è®¡æ•°å™¨æ€»æ˜¯é‡ç½®ï¼ˆé¿å…é‡å¤è®¡æ•°ï¼‰
                        # è®¡æ•°å™¨æ˜¯å¢é‡æ•°æ®ï¼Œä¸èƒ½ç´¯åŠ ï¼›histogram æ˜¯ç´¯ç§¯æ•°æ®ï¼Œå¯ä»¥ä¿ç•™
                        local_stats.messages_sent = 0
                        local_stats.bytes_sent = 0
                        local_stats.errors = 0

                        # ğŸ”§ FIX Bug #2: Histogram æ”¹ä¸ºç´¯ç§¯è¯­ä¹‰ï¼ˆä¸é‡ç½®ï¼‰ï¼Œä¸ Consumer ä¿æŒä¸€è‡´
                        # Histogram æ°¸è¿œä¸é‡ç½®ï¼Œç´¯ç§¯æ•´ä¸ªæµ‹è¯•æœŸé—´çš„æ‰€æœ‰æ ·æœ¬
                        # å¦‚æœé˜Ÿåˆ—æ»¡å¯¼è‡´å‘é€å¤±è´¥ï¼Œhistogram ä¿ç•™ï¼Œä¸‹æ¬¡ä¼šé‡æ–°å‘é€å®Œæ•´çš„ç´¯ç§¯æ•°æ®
                        # ä¸»è¿›ç¨‹ä¼šåœ¨æ¯æ¬¡ get_period_stats() æ—¶åˆå¹¶æ‰€æœ‰ Agent çš„ histogram
                        # ç„¶åä½¿ç”¨ Recorder çš„åŒç¼“å†²æœºåˆ¶è·å–å¢é‡æ•°æ®

                    except Exception as e:
                        logger.error(f"Agent {agent_id} failed to send stats: {e}", exc_info=True)
                        # âœ… å¼‚å¸¸æ—¶ä¹Ÿè¦é‡ç½®è®¡æ•°å™¨ï¼ˆé¿å…é‡å¤è®¡æ•°ï¼‰
                        # Histogram ä¿ç•™ï¼Œä¸‹æ¬¡ä¼šé‡æ–°å‘é€å®Œæ•´æ•°æ®
                        local_stats.messages_sent = 0
                        local_stats.bytes_sent = 0
                        local_stats.errors = 0

                    last_stats_report = now

            except KeyboardInterrupt:
                logger.info(f"Agent {agent_id} received keyboard interrupt, stopping...")
                break
            except Exception as e:
                logger.error(f"Agent {agent_id} error in send loop: {e}", exc_info=True)
                local_stats.errors += 1

                # æ ¹æ®é”™è¯¯ç±»å‹é‡‡å–ä¸åŒçš„æ¢å¤ç­–ç•¥
                error_str = str(e).lower()
                if 'broker' in error_str or 'connection' in error_str or 'network' in error_str:
                    # ç½‘ç»œ/è¿æ¥é”™è¯¯ - ç­‰å¾…è¾ƒé•¿æ—¶é—´åé‡è¯•
                    logger.warning(f"Agent {agent_id} detected connection error, backing off for 1s")
                    time.sleep(1.0)
                elif 'queue' in error_str or 'buffer' in error_str:
                    # é˜Ÿåˆ—/ç¼“å†²åŒºé”™è¯¯ - ç­‰å¾…ä¸­ç­‰æ—¶é—´
                    logger.warning(f"Agent {agent_id} detected queue/buffer error, backing off for 100ms")
                    time.sleep(0.1)
                else:
                    # å…¶ä»–é”™è¯¯ - çŸ­æš‚ç­‰å¾…
                    time.sleep(0.01)

                # è¿ç»­é”™è¯¯æ£€æµ‹ï¼šå¦‚æœé”™è¯¯ç‡è¿‡é«˜ï¼Œåœæ­¢Agent
                if local_stats.errors > 100 and message_count > 0:
                    error_rate = local_stats.errors / message_count
                    if error_rate > 0.5:  # é”™è¯¯ç‡è¶…è¿‡50%
                        logger.error(f"Agent {agent_id} error rate too high ({error_rate:.1%}), stopping")
                        break

        logger.info(f"Agent {agent_id} stopping gracefully (sent {message_count} messages total)")

    except Exception as e:
        logger.error(f"Agent {agent_id} fatal error: {e}", exc_info=True)
        # å‘é€é”™è¯¯ä¿¡å·ç»™ä¸»è¿›ç¨‹
        try:
            ready_queue.put({'agent_id': agent_id, 'status': 'error', 'type': 'producer', 'error': str(e)}, timeout=0.5)
        except:
            pass

    finally:
        # 7. æ¸…ç†èµ„æº
        try:
            # Flushæ‰€æœ‰å¾…å‘é€æ¶ˆæ¯
            producer.flush(10)
            logger.info(f"Agent {agent_id} flushed pending messages")
        except Exception as e:
            logger.error(f"Agent {agent_id} error flushing producer: {e}")

        # 8. å‘é€æœ€ç»ˆç»Ÿè®¡
        try:
            final_stats = {
                'agent_id': agent_id,
                'final': True,
                'total_messages': message_count
            }
            stats_queue.put(final_stats, timeout=1.0)
        except Exception as e:
            logger.error(f"Agent {agent_id} error sending final stats: {e}")

        logger.info(f"Agent {agent_id} terminated")
