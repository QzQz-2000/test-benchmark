# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
# http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

"""
LocalWorker - å¤šè¿›ç¨‹ISOLATEDæ¶æ„
æ¯ä¸ªProducerä½œä¸ºç‹¬ç«‹è¿›ç¨‹è¿è¡Œï¼Œæ¨¡æ‹ŸçœŸå®çš„æ•°å­—å­ªç”ŸAgent

è¿™æ˜¯å”¯ä¸€çš„LocalWorkerå®ç°ï¼ˆæ—§çš„SHAREDå¤šçº¿ç¨‹æ¨¡å¼å·²åºŸå¼ƒï¼‰
"""

import logging
import multiprocessing
import threading
import time
import importlib
from typing import List
from .worker import Worker
from .worker_stats import WorkerStats
from .isolated_agent_worker import isolated_agent_worker
from .isolated_consumer_agent import isolated_consumer_agent
from .commands.consumer_assignment import ConsumerAssignment
from .commands.counters_stats import CountersStats
from .commands.cumulative_latencies import CumulativeLatencies
from .commands.period_stats import PeriodStats
from .commands.producer_work_assignment import ProducerWorkAssignment
from .commands.topics_info import TopicsInfo

logger = logging.getLogger(__name__)


class LocalWorker(Worker):
    """
    LocalWorker - å¤šè¿›ç¨‹ISOLATEDæ¶æ„

    æ¯ä¸ªAgentä½œä¸ºç‹¬ç«‹è¿›ç¨‹è¿è¡Œï¼Œå®Œå…¨éš”ç¦»
    é€‚ç”¨äºæ•°å­—å­ªç”Ÿåœºæ™¯ï¼šIoTè®¾å¤‡ã€è‡ªåŠ¨é©¾é©¶è½¦è¾†ã€æ™ºèƒ½åˆ¶é€ è®¾å¤‡ç­‰

    ç‰¹æ€§:
    - çœŸå®ç‹¬ç«‹: æ¯ä¸ªAgentç‹¬ç«‹è¿›ç¨‹ï¼Œå®Œå…¨éš”ç¦»
    - çœŸå®è¿æ¥: æ¯ä¸ªAgentç‹¬ç«‹Kafkaè¿æ¥
    - æ— GILé™åˆ¶: çœŸæ­£å¹¶è¡Œæ‰§è¡Œ
    - åŠ¨æ€é€Ÿç‡: æ”¯æŒè¿è¡Œæ—¶é€Ÿç‡è°ƒæ•´
    - ç»Ÿè®¡èšåˆ: è‡ªåŠ¨æ”¶é›†æ‰€æœ‰Agentç»Ÿè®¡
    """

    def __init__(self, stats_logger=None):
        """
        Initialize local worker in ISOLATED mode.

        :param stats_logger: Optional stats logger
        """
        self.benchmark_driver = None
        self.producers = []  # Producerå…ƒæ•°æ®ï¼ˆä¸æ˜¯å®é™…å¯¹è±¡ï¼ŒAgentè¿›ç¨‹å†…åˆ›å»ºï¼‰
        self.consumers = []  # V1å…¼å®¹æ€§ä¿ç•™ï¼ˆå°†æ¥å¯ä»¥åˆ é™¤ï¼‰
        self.consumer_metadata = []  # Consumerå…ƒæ•°æ®ï¼ˆV2æ¶æ„ï¼šæ¯ä¸ªConsumerç‹¬ç«‹è¿›ç¨‹ï¼‰
        self.executor = None
        self.stats = WorkerStats(stats_logger)
        self.test_completed = multiprocessing.Event()
        self.consumers_are_paused = False
        self._lock = threading.Lock()

        # ISOLATEDæ¨¡å¼æ ¸å¿ƒç»„ä»¶
        self.agent_processes = []  # Agentè¿›ç¨‹åˆ—è¡¨
        self.stop_agents = multiprocessing.Event()  # Agentåœæ­¢ä¿¡å·
        self.start_producing_event = multiprocessing.Event()  # Producerå¼€å§‹å‘é€ä¿¡å·ï¼ˆç­‰å¾…Consumerç¨³å®šï¼‰
        self.pause_consumers_event = multiprocessing.Event()  # Consumeræš‚åœä¿¡å·ï¼ˆç”¨äºbacklogæ¨¡å¼ï¼‰

        # ğŸ”§ FIX Bug #5: å¢å¤§é˜Ÿåˆ—å®¹é‡ä»¥å‡å°‘æ•°æ®ä¸¢å¤±
        # é˜Ÿåˆ—å®¹é‡è®¾ç½®ï¼ˆè€ƒè™‘ç³»ç»Ÿé™åˆ¶ï¼‰
        # - macOS: ä¿¡å·é‡ä¸Šé™ 32767
        # - Linux: é€šå¸¸æ›´å¤§ï¼ˆå¯ä»¥åˆ°å‡ ç™¾ä¸‡ï¼‰
        # ç­–ç•¥ï¼šä½¿ç”¨ç³»ç»Ÿå…è®¸çš„æœ€å¤§å€¼ï¼Œå¹¶æ·»åŠ ç›‘æ§
        import platform
        if platform.system() == 'Darwin':  # macOS
            max_queue_size = 32000  # ä¿å®ˆå€¼ï¼Œé¿å…è¾¾åˆ°ç³»ç»Ÿé™åˆ¶
        else:  # Linux å’Œå…¶ä»–ç³»ç»Ÿ
            max_queue_size = 100000  # æ›´å¤§çš„å®¹é‡ï¼Œæ”¯æŒæ›´å¤š Agent

        logger.info(f"Stats queue max size: {max_queue_size} (platform: {platform.system()})")

        self.stats_queue = multiprocessing.Queue(maxsize=max_queue_size)  # è·¨è¿›ç¨‹ç»Ÿè®¡é˜Ÿåˆ—
        self.stats_queue_max_size = max_queue_size  # ä¿å­˜æœ€å¤§å®¹é‡ç”¨äºç›‘æ§
        self.shared_publish_rate = multiprocessing.Value('d', 1.0)  # å…±äº«é€Ÿç‡ï¼ˆæ”¯æŒåŠ¨æ€è°ƒæ•´ï¼‰
        self.reset_stats_flag = multiprocessing.Value('i', 0)  # é‡ç½®ç»Ÿè®¡æ ‡å¿—ï¼ˆepochè®¡æ•°å™¨ï¼‰
        self.agent_ready_queue = multiprocessing.Queue(maxsize=max_queue_size)  # Agentå°±ç»ª/é”™è¯¯ä¿¡å·é˜Ÿåˆ—

        # ç»Ÿè®¡æ”¶é›†çº¿ç¨‹
        self.stats_collector_thread = None
        self.stats_collector_running = False

        logger.info("LocalWorker initialized (multi-process ISOLATED architecture)")

    def initialize_driver(self, configuration_file: str):
        """Initialize the benchmark driver."""
        import yaml

        # å…è®¸é‡æ–°åˆå§‹åŒ–ï¼ˆåˆ†å¸ƒå¼æ¨¡å¼ä¸‹å¯èƒ½ä¼šå¤šæ¬¡è°ƒç”¨ï¼‰
        if self.benchmark_driver is not None:
            logger.warning("Driver already initialized, closing previous driver and reinitializing")
            try:
                self.benchmark_driver.close()
            except Exception as e:
                logger.warning(f"Error closing previous driver: {e}")
            self.benchmark_driver = None

            # ğŸ”§ FIX: æ¸…ç†æ‰€æœ‰çŠ¶æ€ï¼Œé¿å…å¤šæ¬¡æµ‹è¯•æ—¶çš„æ•°æ®æ®‹ç•™
            logger.info("Cleaning up previous test state...")

            # 1. æ¸…ç©º producer/consumer å…ƒæ•°æ®
            self.producers = []
            self.consumer_metadata = []

            # 2. æ¸…ç©ºç»Ÿè®¡é˜Ÿåˆ—ä¸­çš„æ®‹ç•™æ•°æ®
            drained = 0
            try:
                while not self.stats_queue.empty():
                    self.stats_queue.get_nowait()
                    drained += 1
            except:
                pass
            if drained > 0:
                logger.info(f"Drained {drained} stale stats from queue")

            # 3. æ¸…ç©º ready é˜Ÿåˆ—
            drained_ready = 0
            try:
                while not self.agent_ready_queue.empty():
                    self.agent_ready_queue.get_nowait()
                    drained_ready += 1
            except:
                pass
            if drained_ready > 0:
                logger.info(f"Drained {drained_ready} stale ready signals from queue")

            # 4. é‡ç½®ç»Ÿè®¡å¯¹è±¡
            self.stats.reset()

            # 5. é€’å¢ epoch è®¡æ•°å™¨ï¼ˆè€Œä¸æ˜¯é‡ç½®ä¸º0ï¼‰
            # è¿™æ ·å¯ä»¥ç¡®ä¿ç¬¬äºŒæ¬¡æµ‹è¯•çš„ epoch > ç¬¬ä¸€æ¬¡æµ‹è¯•ï¼Œç»Ÿè®¡æ”¶é›†çº¿ç¨‹å¯ä»¥ä¸¢å¼ƒæ—§æ•°æ®
            old_epoch = self.reset_stats_flag.value
            new_epoch = old_epoch + 1
            self.reset_stats_flag.value = new_epoch
            logger.info(f"Incrementing epoch: {old_epoch} -> {new_epoch}")

            # 6. é‡ç½®æ‰€æœ‰ Event çŠ¶æ€
            self.stop_agents.clear()
            self.start_producing_event.clear()
            self.pause_consumers_event.clear()
            self.test_completed.clear()

            # 7. é‡ç½®å…±äº«é€Ÿç‡
            self.shared_publish_rate.value = 1.0

            # 8. æ¸…ç©º agent è¿›ç¨‹åˆ—è¡¨ï¼ˆåº”è¯¥å·²ç»è¢« stop_all æ¸…ç†äº†ï¼‰
            self.agent_processes = []

            # 9. åœæ­¢æ—§çš„ç»Ÿè®¡æ”¶é›†çº¿ç¨‹ï¼ˆå¦‚æœè¿˜åœ¨è¿è¡Œï¼‰
            if self.stats_collector_running:
                logger.warning("Stats collector was still running, stopping it...")
                self.stats_collector_running = False
                if self.stats_collector_thread and self.stats_collector_thread.is_alive():
                    self.stats_collector_thread.join(timeout=2.0)
                    if self.stats_collector_thread.is_alive():
                        logger.error("Stats collector thread did not stop!")
                logger.info("Stats collector stopped during cleanup")

            logger.info("Previous test state cleaned")

        self.test_completed.clear()

        # Load driver configuration
        with open(configuration_file, 'r') as f:
            driver_config = yaml.safe_load(f)

        logger.info(f"Driver config: {driver_config}")

        try:
            # Dynamically load driver class
            driver_class_name = driver_config['driverClass']
            module_name, class_name = driver_class_name.rsplit('.', 1)
            module = importlib.import_module(module_name)
            driver_class = getattr(module, class_name)

            # Instantiate driver
            self.benchmark_driver = driver_class()
            self.benchmark_driver.initialize(configuration_file, self.stats.get_stats_logger())

        except Exception as e:
            raise RuntimeError(f"Failed to initialize driver: {e}") from e

    def create_topics(self, topics_info: TopicsInfo) -> List[str]:
        """Create topics."""
        if self.benchmark_driver is None:
            raise RuntimeError("Driver not initialized")

        topic_name_prefix = self.benchmark_driver.get_topic_name_prefix()
        topics = []

        for i in range(topics_info.number_of_topics):
            topic_name = f"{topic_name_prefix}-{i}"
            topics.append(topic_name)

        # Create topics using driver
        topic_infos = [
            {'topic': topic, 'partitions': topics_info.number_of_partitions_per_topic}
            for topic in topics
        ]

        # Wait for all topics to be created
        future = self.benchmark_driver.create_topics(topic_infos)
        future.result()  # Block until creation completes, raise exception if failed

        return topics

    def create_producers(self, topics: List[str]):
        """
        Create producer metadata (ä¸åˆ›å»ºå®é™…å¯¹è±¡).
        åœ¨ISOLATEDæ¨¡å¼ä¸‹ï¼Œæ¯ä¸ªAgentè¿›ç¨‹ä¼šåœ¨è‡ªå·±å†…éƒ¨åˆ›å»ºProducer.
        """
        if self.benchmark_driver is None:
            raise RuntimeError("Driver not initialized")

        # åªä¿å­˜å…ƒæ•°æ®
        class ProducerMeta:
            def __init__(self, id, topic):
                self.id = id
                self.topic = topic

        self.producers = [
            ProducerMeta(i, topic)
            for i, topic in enumerate(topics)
        ]

        logger.info(f"Registered {len(self.producers)} producer metadata (Agents will create actual producers)")
        logger.info(f"ğŸ“‹ Producer topics assigned to this worker: {topics}")

    def create_consumers(self, consumer_assignment: ConsumerAssignment):
        """
        Create consumer metadata (V2æ¶æ„ï¼šä¸åˆ›å»ºå®é™…å¯¹è±¡).
        åœ¨V2æ¶æ„ä¸‹ï¼Œæ¯ä¸ªConsumerä½œä¸ºç‹¬ç«‹è¿›ç¨‹è¿è¡Œï¼Œåœ¨è¿›ç¨‹å†…éƒ¨åˆ›å»ºKafka Consumer.
        """
        if self.benchmark_driver is None:
            raise RuntimeError("Driver not initialized")

        # V2: åªä¿å­˜Consumerå…ƒæ•°æ®
        class ConsumerMeta:
            def __init__(self, id, topic, subscription):
                self.id = id
                self.topic = topic
                self.subscription = subscription

        self.consumer_metadata = [
            ConsumerMeta(i, ts.topic, ts.subscription)
            for i, ts in enumerate(consumer_assignment.topics_subscriptions)
        ]

        logger.info(f"Registered {len(self.consumer_metadata)} consumer metadata (V2: Agents will create actual consumers)")
        consumer_topics = [ts.topic for ts in consumer_assignment.topics_subscriptions]
        logger.info(f"ğŸ“‹ Consumer topics assigned to this worker: {consumer_topics}")

    def probe_producers(self):
        """
        Probe producers by sending one test message per topic.
        åœ¨ISOLATEDæ¨¡å¼ä¸‹ï¼Œæˆ‘ä»¬ç›´æ¥ä½¿ç”¨driverå‘é€æµ‹è¯•æ¶ˆæ¯åˆ°æ¯ä¸ªtopic.
        """
        import time
        logger.info("Probing topics with test messages")

        if not self.producers:
            return

        # Get unique topics from all producers
        unique_topics = list(set(p.topic for p in self.producers))
        logger.info(f"Sending probe message to {len(unique_topics)} topics: {unique_topics}")

        # Send one probe message to each topic
        test_producers = []
        for topic in unique_topics:
            test_producer_future = self.benchmark_driver.create_producer(topic)
            test_producer = test_producer_future.result()
            test_producers.append(test_producer)

            # Record the send in stats
            self.stats.record_message_sent()

            # Send probe message
            test_producer.send_async(None, b"probe")
            logger.info(f"Sent probe message to topic: {topic}")

        # Wait for messages to be delivered
        time.sleep(1.0)

        # Close all test producers
        for test_producer in test_producers:
            test_producer.close()

        time.sleep(1.0)
        logger.info(f"Probe complete: sent {len(unique_topics)} messages to {len(unique_topics)} topics")

    def start_load(self, producer_work_assignment: ProducerWorkAssignment, message_processing_delay_ms: int = 0):
        """
        å¯åŠ¨è´Ÿè½½ç”Ÿæˆ - V2 ISOLATEDæ¨¡å¼
        ä¸ºæ¯ä¸ªProduceråˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„Agentè¿›ç¨‹
        ä¸ºæ¯ä¸ªConsumeråˆ›å»ºä¸€ä¸ªç‹¬ç«‹çš„Agentè¿›ç¨‹

        :param producer_work_assignment: Producerå·¥ä½œåˆ†é…é…ç½®
        :param message_processing_delay_ms: æ¶ˆæ¯å¤„ç†å»¶è¿Ÿï¼ˆæ¯«ç§’ï¼‰ï¼Œç”¨äºæ¨¡æ‹Ÿæ…¢é€Ÿæ¶ˆè´¹è€…
        """
        if not self.producers and not self.consumer_metadata:
            logger.error("No producers or consumers registered, cannot start load")
            return

        publish_rate = producer_work_assignment.publish_rate
        num_producer_agents = len(self.producers)
        num_consumer_agents = len(self.consumer_metadata)
        total_agents = num_producer_agents + num_consumer_agents

        logger.info(f"=" * 80)
        logger.info(f"Starting V2 ISOLATED mode: {total_agents} independent Agent processes")
        logger.info(f"  - Producer Agents: {num_producer_agents} (each @ {publish_rate} msg/s)")
        logger.info(f"  - Consumer Agents: {num_consumer_agents}")
        logger.info(f"Total publish throughput: {num_producer_agents * publish_rate} msg/s")
        logger.info(f"=" * 80)

        # è®¾ç½®å…±äº«é€Ÿç‡
        self.shared_publish_rate.value = publish_rate
        self.stop_agents.clear()

        # æ£€æµ‹é©±åŠ¨ç±»å‹å¹¶è·å–é…ç½®
        # Pulsaré©±åŠ¨æœ‰get_client_properties()æ–¹æ³•ï¼ŒKafkaé©±åŠ¨æ²¡æœ‰
        is_pulsar = hasattr(self.benchmark_driver, 'get_client_properties')

        if is_pulsar:
            # Pulsaré…ç½®
            logger.info("Detected Pulsar driver, using Pulsar agent workers")
            from .isolated_pulsar_agent_worker import isolated_pulsar_agent_worker
            from .isolated_pulsar_consumer_agent import isolated_pulsar_consumer_agent

            pulsar_client_config = self.benchmark_driver.get_client_properties()
            pulsar_producer_config = self.benchmark_driver.get_producer_properties()
            pulsar_consumer_config = self.benchmark_driver.get_consumer_properties()

            producer_worker_func = isolated_pulsar_agent_worker
            consumer_worker_func = isolated_pulsar_consumer_agent
        else:
            # Kafkaé…ç½®ï¼ˆé»˜è®¤ï¼‰
            logger.info("Detected Kafka driver, using Kafka agent workers")
            kafka_producer_config = self.benchmark_driver.get_producer_properties()
            kafka_consumer_config = self.benchmark_driver.get_consumer_properties()

            producer_worker_func = isolated_agent_worker
            consumer_worker_func = isolated_consumer_agent

        # æ¸…ç†æ—§çš„ç»Ÿè®¡æ–‡ä»¶ï¼ˆæ–‡ä»¶è¾“å‡ºæ¨¡å¼ï¼‰
        self._cleanup_old_stats_files()

        # å¯åŠ¨ç»Ÿè®¡æ”¶é›†çº¿ç¨‹
        self._start_stats_collector()

        # 1. ä¸ºæ¯ä¸ªProduceråˆ›å»ºç‹¬ç«‹çš„Agentè¿›ç¨‹
        for i, producer_meta in enumerate(self.producers):
            if is_pulsar:
                # Pulsar agent arguments
                process = multiprocessing.Process(
                    target=producer_worker_func,
                    args=(
                        i,                              # agent_id
                        producer_meta.topic,            # topic
                        pulsar_client_config,           # Pulsar client config
                        pulsar_producer_config,         # Pulsar producer config
                        producer_work_assignment,       # work assignment
                        self.stop_agents,               # stop event
                        self.stats_queue,               # stats queue
                        self.shared_publish_rate,       # shared rate (for dynamic adjustment)
                        self.reset_stats_flag,          # reset stats flag
                        self.agent_ready_queue          # ready/error queue
                    ),
                    name=f"pulsar-producer-agent-{i}",
                    daemon=False
                )
            else:
                # Kafka agent arguments
                process = multiprocessing.Process(
                    target=producer_worker_func,
                    args=(
                        i,                              # agent_id
                        producer_meta.topic,            # topic
                        kafka_producer_config,          # Kafka producer config
                        kafka_consumer_config,          # Kafka consumer config
                        producer_work_assignment,       # work assignment
                        self.stop_agents,               # stop event
                        self.stats_queue,               # stats queue
                        self.shared_publish_rate,       # shared rate (for dynamic adjustment)
                        self.reset_stats_flag,          # reset stats flag
                        self.agent_ready_queue,         # ready/error queue
                        self.start_producing_event      # start producing event (wait for consumers)
                    ),
                    name=f"kafka-producer-agent-{i}",
                    daemon=False  # édaemonï¼Œç¡®ä¿æ­£å¸¸å…³é—­
                )

            process.start()
            self.agent_processes.append(process)

        logger.info(f"Started {num_producer_agents} Producer Agent processes")

        # 2. ä¸ºæ¯ä¸ªConsumeråˆ›å»ºç‹¬ç«‹çš„Agentè¿›ç¨‹ (V2æ–°å¢)
        # âœ… ä¼˜åŒ–ï¼šå»¶è¿Ÿå¯åŠ¨ï¼Œå‡å°‘ Consumer Group Rebalance é£æš´
        consumer_start_delay_ms = 150  # æ¯ä¸ª consumer å¯åŠ¨é—´éš” 150ms

        # Agent ID å¿…é¡»è¿ç»­ä¸”å”¯ä¸€ï¼šProducerç”¨0åˆ°num_producer_agents-1ï¼ŒConsumerä»num_producer_agentså¼€å§‹
        for i, consumer_meta in enumerate(self.consumer_metadata):
            agent_id = num_producer_agents + i  # Consumer agent ID ä» producer æ•°é‡åå¼€å§‹
            if is_pulsar:
                # Pulsar consumer agent arguments
                process = multiprocessing.Process(
                    target=consumer_worker_func,
                    args=(
                        agent_id,                       # agent_id (unique across all agents)
                        consumer_meta.topic,            # topic
                        consumer_meta.subscription,     # subscription name
                        pulsar_client_config,           # Pulsar client config
                        pulsar_consumer_config,         # Pulsar consumer config
                        self.stop_agents,               # stop event
                        self.stats_queue,               # stats queue
                        self.reset_stats_flag,          # reset stats flag
                        self.agent_ready_queue,         # ready/error queue
                        self.pause_consumers_event,     # pause event (for backlog mode)
                        message_processing_delay_ms     # message processing delay (for slow consumer simulation)
                    ),
                    name=f"pulsar-consumer-agent-{agent_id}",
                    daemon=False
                )
            else:
                # Kafka consumer agent arguments
                process = multiprocessing.Process(
                    target=consumer_worker_func,
                    args=(
                        agent_id,                       # agent_id (unique across all agents)
                        consumer_meta.topic,            # topic
                        consumer_meta.subscription,     # subscription name
                        kafka_consumer_config,          # Kafka consumer config
                        self.stop_agents,               # stop event
                        self.stats_queue,               # stats queue
                        self.reset_stats_flag,          # reset stats flag
                        self.agent_ready_queue,         # ready/error queue
                        self.pause_consumers_event,     # pause event (for backlog mode)
                        message_processing_delay_ms     # message processing delay (for slow consumer simulation)
                    ),
                    name=f"kafka-consumer-agent-{agent_id}",
                    daemon=False
                )

            process.start()
            self.agent_processes.append(process)

            # âœ… å»¶è¿Ÿå¯åŠ¨ï¼šé¿å…æ‰€æœ‰ consumer åŒæ—¶åŠ å…¥ groupï¼Œå‡å°‘ rebalance æ¬¡æ•°
            if i < len(self.consumer_metadata) - 1:  # æœ€åä¸€ä¸ªä¸éœ€è¦ç­‰å¾…
                time.sleep(consumer_start_delay_ms / 1000.0)
                logger.debug(f"Started Consumer Agent {i}, waiting {consumer_start_delay_ms}ms before next...")

        logger.info(f"Started {num_consumer_agents} Consumer Agent processes")
        logger.info(f"Total: {len(self.agent_processes)} Agent processes running")

        # ç­‰å¾…æ‰€æœ‰Agentå‘é€å°±ç»ªä¿¡å·ï¼ˆæˆ–é”™è¯¯ï¼‰
        ready_count = 0
        errors = []
        # æ ¹æ®Agentæ•°é‡åŠ¨æ€è°ƒæ•´è¶…æ—¶æ—¶é—´: åŸºç¡€10ç§’ + æ¯ä¸ªAgent 0.5ç§’
        timeout_total = 10.0 + (total_agents * 0.5)
        deadline = time.time() + timeout_total
        logger.info(f"Waiting for {total_agents} Agents to report ready (timeout: {timeout_total:.1f}s)")

        for i in range(total_agents):
            remaining = max(0.1, deadline - time.time())
            try:
                msg = self.agent_ready_queue.get(timeout=remaining)
                agent_id = msg.get('agent_id')
                agent_type = msg.get('type', 'unknown')
                status = msg.get('status')

                if status == 'ready':
                    ready_count += 1
                    logger.info(f"{agent_type.capitalize()} Agent {agent_id} is ready ({ready_count}/{total_agents})")
                elif status == 'error':
                    error_msg = msg.get('error', 'Unknown error')
                    errors.append(f"{agent_type.capitalize()} Agent {agent_id}: {error_msg}")
                    logger.error(f"{agent_type.capitalize()} Agent {agent_id} failed to start: {error_msg}")
            except:
                # è¶…æ—¶ï¼Œæ£€æŸ¥è¿›ç¨‹çŠ¶æ€
                break

        # æœ€ç»ˆå¥åº·æ£€æŸ¥
        alive_count = sum(1 for p in self.agent_processes if p.is_alive())
        logger.info(f"Agent startup complete: {ready_count} ready, {alive_count} alive, {len(errors)} errors")

        if errors:
            error_summary = "; ".join(errors[:5])  # åªæ˜¾ç¤ºå‰5ä¸ªé”™è¯¯
            raise RuntimeError(f"Failed to start {len(errors)} Agent(s): {error_summary}")

        if ready_count < total_agents:
            logger.warning(f"Warning: Only {ready_count}/{total_agents} Agents reported ready (timeout or crash)")

        # âœ… ä¼˜åŒ–ï¼šç­‰å¾… Consumer Group Rebalance å®Œå…¨ç¨³å®š
        # å½“æ‰€æœ‰ consumer åŠ å…¥åï¼ŒKafka éœ€è¦æ—¶é—´å®Œæˆæœ€ç»ˆçš„åˆ†åŒºåˆ†é…å’Œç¨³å®š
        if num_consumer_agents > 0:
            # æ ¹æ® consumer æ•°é‡åŠ¨æ€è°ƒæ•´ç­‰å¾…æ—¶é—´
            # ç»éªŒå€¼ï¼šåŸºç¡€ 5 ç§’ + æ¯ä¸ª consumer 0.3 ç§’
            stabilization_time = 5.0 + (num_consumer_agents * 0.3)
            logger.info(f"=" * 80)
            logger.info(f"â³ Waiting {stabilization_time:.1f}s for Consumer Group rebalance to stabilize...")
            logger.info(f"   This ensures all consumers have settled on their partition assignments")
            logger.info(f"   Producer Agents are paused, waiting for start signal")
            logger.info(f"=" * 80)
            time.sleep(stabilization_time)
            logger.info("âœ… Consumer Group should now be stable")

        logger.info("âœ… All Agents ready, waiting for workload start signal...")

    def _cleanup_old_stats_files(self):
        """æ¸…ç†æ—§çš„ç»Ÿè®¡æ–‡ä»¶ï¼ˆæ¯æ¬¡æµ‹è¯•å¼€å§‹æ—¶è°ƒç”¨ï¼‰"""
        from pathlib import Path
        stats_dir = Path("/tmp/kafka_benchmark_stats")

        if not stats_dir.exists():
            logger.info("Stats directory does not exist, no cleanup needed")
            return

        deleted = 0
        try:
            # åˆ é™¤æ‰€æœ‰ .pkl æ–‡ä»¶
            for stats_file in stats_dir.glob("*.pkl"):
                try:
                    stats_file.unlink()
                    deleted += 1
                except Exception as e:
                    logger.warning(f"Failed to delete {stats_file}: {e}")

            # åˆ é™¤æ‰€æœ‰ .tmp æ–‡ä»¶
            for temp_file in stats_dir.glob("*.tmp"):
                try:
                    temp_file.unlink()
                    deleted += 1
                except Exception as e:
                    logger.warning(f"Failed to delete {temp_file}: {e}")

            if deleted > 0:
                logger.info(f"Cleaned up {deleted} old stats files from {stats_dir}")
            else:
                logger.info("No old stats files to clean up")
        except Exception as e:
            logger.error(f"Error cleaning up stats files: {e}")

    def _start_stats_collector(self):
        """å¯åŠ¨ç»Ÿè®¡æ”¶é›†çº¿ç¨‹ï¼ˆä»Agentè¿›ç¨‹æ”¶é›†ç»Ÿè®¡ï¼‰"""
        self.stats_collector_running = True

        def collector_loop():
            """ç»Ÿè®¡æ”¶é›†çº¿ç¨‹ä¸»å¾ªç¯"""
            from hdrh.histogram import HdrHistogram

            logger.info("Stats collector thread started")

            # ğŸ”§ FIX Bug #5: æ·»åŠ é˜Ÿåˆ—ç›‘æ§
            queue_full_warnings = 0
            last_queue_size_log = time.time()

            while self.stats_collector_running:
                try:
                    # ğŸ”§ FIX Bug #5: å®šæœŸç›‘æ§é˜Ÿåˆ—å¤§å°ï¼ˆæ¯10ç§’ï¼‰
                    # æ³¨æ„ï¼šmacOS ä¸æ”¯æŒ qsize()ï¼Œæ‰€ä»¥ä½¿ç”¨ try-except è·³è¿‡ç›‘æ§
                    now = time.time()
                    if now - last_queue_size_log > 10.0:
                        try:
                            queue_size = self.stats_queue.qsize()
                            utilization = (queue_size / self.stats_queue_max_size) * 100 if self.stats_queue_max_size > 0 else 0

                            if utilization > 80:
                                logger.warning(f"âš ï¸  Stats queue high utilization: {queue_size}/{self.stats_queue_max_size} ({utilization:.1f}%)")
                                queue_full_warnings += 1
                            elif utilization > 50:
                                logger.info(f"Stats queue size: {queue_size}/{self.stats_queue_max_size} ({utilization:.1f}%)")
                        except NotImplementedError:
                            # macOS ä¸æ”¯æŒ qsize()ï¼Œè·³è¿‡é˜Ÿåˆ—ç›‘æ§
                            pass

                        last_queue_size_log = now

                    # éé˜»å¡è·å–ç»Ÿè®¡æ•°æ®ï¼ˆtimeout=0.5ç§’ï¼‰
                    try:
                        stats_dict = self.stats_queue.get(timeout=0.5)
                    except:
                        continue

                    agent_id = stats_dict.get('agent_id')

                    # æ£€æŸ¥æ˜¯å¦æ˜¯æœ€ç»ˆç»Ÿè®¡
                    if stats_dict.get('final'):
                        logger.debug(f"Agent {agent_id} sent final stats: {stats_dict.get('total_messages')} total messages")
                        continue

                    # æ£€æŸ¥epochï¼Œä¸¢å¼ƒæ—§epochçš„æ•°æ®
                    stats_epoch = stats_dict.get('epoch', 0)
                    current_epoch = self.reset_stats_flag.value
                    if stats_epoch < current_epoch:
                        logger.debug(f"Dropping stats from Agent {agent_id}: old epoch {stats_epoch} < current {current_epoch}")
                        continue

                    # åŒºåˆ†Producerå’ŒConsumerç»Ÿè®¡
                    agent_type = stats_dict.get('type', 'producer')

                    if agent_type == 'producer':
                        # Producerç»Ÿè®¡
                        messages_sent = stats_dict.get('messages_sent', 0)
                        bytes_sent = stats_dict.get('bytes_sent', 0)
                        errors = stats_dict.get('errors', 0)

                        # æ›´æ–°ä¸»ç»Ÿè®¡å¯¹è±¡ï¼ˆåŸå­æ“ä½œï¼‰
                        if messages_sent > 0:
                            self.stats.messages_sent.add(messages_sent)
                            self.stats.total_messages_sent.add(messages_sent)
                        if bytes_sent > 0:
                            self.stats.bytes_sent.add(bytes_sent)
                            self.stats.total_bytes_sent.add(bytes_sent)
                        if errors > 0:
                            self.stats.message_send_errors.add(errors)
                            self.stats.total_message_send_errors.add(errors)

                    elif agent_type == 'consumer':
                        # Consumerç»Ÿè®¡ (V2æ–°å¢)
                        messages_received = stats_dict.get('messages_received', 0)
                        bytes_received = stats_dict.get('bytes_received', 0)

                        # æ›´æ–°ä¸»ç»Ÿè®¡å¯¹è±¡
                        if messages_received > 0:
                            self.stats.messages_received.add(messages_received)
                            self.stats.total_messages_received.add(messages_received)
                        if bytes_received > 0:
                            self.stats.bytes_received.add(bytes_received)
                            self.stats.total_bytes_received.add(bytes_received)

                    # å¤„ç†å»¶è¿Ÿç»Ÿè®¡ï¼šåˆå¹¶Agentçš„histogramåˆ°ä¸»histogramï¼ˆä¸Javaç‰ˆæœ¬ä¸€è‡´ï¼‰
                    # Javaç‰ˆæœ¬ï¼šæ¯ä¸ªworkeræœ‰è‡ªå·±çš„Recorderï¼Œå®šæœŸåˆå¹¶
                    # Pythonç‰ˆæœ¬ï¼šä»Agentè¿›ç¨‹æ”¶é›†ç¼–ç åçš„histogramï¼Œè§£ç å¹¶åˆå¹¶åˆ°Recorderå’Œç´¯ç§¯histogram
                    # Recorderç”¨äºå‘¨æœŸç»Ÿè®¡(get_interval_histogram)ï¼Œcumulativeç”¨äºç´¯ç§¯ç»Ÿè®¡

                    # Producer: å‘å¸ƒå»¶è¿Ÿ
                    if agent_type == 'producer':
                        pub_latency_encoded = stats_dict.get('pub_latency_histogram_encoded')
                        pub_delay_encoded = stats_dict.get('pub_delay_histogram_encoded')

                        if pub_latency_encoded:
                            try:
                                # è§£ç histogram
                                agent_pub_latency_hist = HdrHistogram.decode(pub_latency_encoded)

                                # é«˜æ•ˆåˆå¹¶åˆ°Recorderï¼ˆç”¨äºå‘¨æœŸç»Ÿè®¡ï¼‰- O(n)å¤æ‚åº¦ï¼Œnä¸ºbucketæ•°é‡
                                self.stats.publish_latency_recorder.record_histogram(agent_pub_latency_hist)

                                # åˆå¹¶åˆ°ç´¯ç§¯ç›´æ–¹å›¾ï¼ˆç”¨äºç´¯ç§¯ç»Ÿè®¡ï¼‰
                                with self.stats.histogram_lock:
                                    self.stats.cumulative_publish_latency.add(agent_pub_latency_hist)

                                logger.debug(f"ğŸ“Š åˆå¹¶Agent {agent_id}çš„pub latency histogram (count={agent_pub_latency_hist.get_total_count()})")
                            except Exception as e:
                                logger.warning(f"Failed to decode/merge publish latency histogram from Agent {agent_id}: {e}")

                        if pub_delay_encoded:
                            try:
                                agent_pub_delay_hist = HdrHistogram.decode(pub_delay_encoded)

                                # é«˜æ•ˆåˆå¹¶åˆ°Recorderï¼ˆç”¨äºå‘¨æœŸç»Ÿè®¡ï¼‰
                                self.stats.publish_delay_latency_recorder.record_histogram(agent_pub_delay_hist)

                                # åˆå¹¶åˆ°ç´¯ç§¯ç›´æ–¹å›¾ï¼ˆç”¨äºç´¯ç§¯ç»Ÿè®¡ï¼‰
                                with self.stats.histogram_lock:
                                    self.stats.cumulative_publish_delay_latency.add(agent_pub_delay_hist)

                                logger.debug(f"ğŸ“Š åˆå¹¶Agent {agent_id}çš„pub delay histogram (count={agent_pub_delay_hist.get_total_count()})")
                            except Exception as e:
                                logger.warning(f"Failed to decode/merge publish delay histogram from Agent {agent_id}: {e}")

                    # Consumer: ç«¯åˆ°ç«¯å»¶è¿Ÿ (V2æ–°å¢)
                    if agent_type == 'consumer':
                        e2e_latency_encoded = stats_dict.get('e2e_latency_histogram_encoded')

                        if e2e_latency_encoded:
                            try:
                                # è§£ç histogram
                                agent_e2e_hist = HdrHistogram.decode(e2e_latency_encoded)

                                # é«˜æ•ˆåˆå¹¶åˆ°Recorderï¼ˆç”¨äºå‘¨æœŸç»Ÿè®¡ï¼‰
                                self.stats.end_to_end_latency_recorder.record_histogram(agent_e2e_hist)

                                # åˆå¹¶åˆ°ç´¯ç§¯ç›´æ–¹å›¾ï¼ˆç”¨äºç´¯ç§¯ç»Ÿè®¡ï¼‰
                                with self.stats.histogram_lock:
                                    self.stats.cumulative_end_to_end_latency.add(agent_e2e_hist)

                                logger.debug(f"ğŸ“Š åˆå¹¶Consumer Agent {agent_id}çš„e2e histogram (count={agent_e2e_hist.get_total_count()})")
                            except Exception as e:
                                logger.warning(f"Failed to decode/merge e2e latency histogram from Consumer Agent {agent_id}: {e}")

                except Exception as e:
                    logger.error(f"Error in stats collector: {e}", exc_info=True)

            logger.info("Stats collector thread stopped")

        self.stats_collector_thread = threading.Thread(
            target=collector_loop,
            name="stats-collector",
            daemon=True
        )
        self.stats_collector_thread.start()

    def adjust_publish_rate(self, publish_rate: float):
        """
        åŠ¨æ€è°ƒæ•´å‘å¸ƒé€Ÿç‡ - ISOLATEDæ¨¡å¼
        æ›´æ–°å…±äº«å˜é‡ï¼Œæ‰€æœ‰Agentè¿›ç¨‹ä¼šå®šæœŸæ£€æŸ¥å¹¶æ›´æ–°è‡ªå·±çš„é€Ÿç‡
        """
        self.shared_publish_rate.value = publish_rate
        logger.info(f"Adjusted publish rate to: {publish_rate} msg/s per Agent (total: {publish_rate * len(self.agent_processes)} msg/s)")

    def pause_consumers(self):
        """
        Pause all consumers (for backlog mode).

        V2æ¶æ„å®ç°ï¼šé€šè¿‡ multiprocessing.Event é€šçŸ¥ Consumer Agent æš‚åœæ¶ˆè´¹
        Consumer Agent ä¼šåœæ­¢å¤„ç†æ¶ˆæ¯ï¼Œä½†ç»§ç»­è°ƒç”¨ poll(0) ç»´æŒå¿ƒè·³ï¼Œé¿å…è¢«è¸¢å‡º group
        """
        with self._lock:
            self.consumers_are_paused = True

            # V1å…¼å®¹ä»£ç ï¼ˆå½“consumer_metadataä¸ºç©ºä¸”consumersæœ‰å€¼æ—¶æ‰æ‰§è¡Œï¼‰
            if not self.consumer_metadata and self.consumers:
                for consumer in self.consumers:
                    consumer.pause()
                logger.info("V1 æ¶æ„: Paused all consumers")
            elif self.consumer_metadata:
                # V2æ¶æ„ï¼šè®¾ç½®æš‚åœäº‹ä»¶ï¼Œé€šçŸ¥æ‰€æœ‰Consumer Agent
                self.pause_consumers_event.set()
                logger.info(f"V2 æ¶æ„: Set pause event for {len(self.consumer_metadata)} Consumer Agents")
                logger.info("Consumer Agents will stop processing messages but maintain heartbeat")

    def resume_consumers(self):
        """
        Resume all consumers (for backlog mode).

        V2æ¶æ„å®ç°ï¼šæ¸…é™¤ multiprocessing.Eventï¼Œé€šçŸ¥ Consumer Agent æ¢å¤æ¶ˆè´¹
        """
        with self._lock:
            self.consumers_are_paused = False

            # V1å…¼å®¹ä»£ç 
            if not self.consumer_metadata and self.consumers:
                for consumer in self.consumers:
                    consumer.resume()
                logger.info("V1 æ¶æ„: Resumed all consumers")
            elif self.consumer_metadata:
                # V2æ¶æ„ï¼šæ¸…é™¤æš‚åœäº‹ä»¶ï¼Œé€šçŸ¥æ‰€æœ‰Consumer Agentæ¢å¤
                self.pause_consumers_event.clear()
                logger.info(f"V2 æ¶æ„: Cleared pause event for {len(self.consumer_metadata)} Consumer Agents")
                logger.info("Consumer Agents will resume processing messages")

    def get_counters_stats(self) -> CountersStats:
        """Get counter statistics."""
        return self.stats.to_counters_stats()

    def get_period_stats(self) -> PeriodStats:
        """Get period statistics."""
        return self.stats.to_period_stats()

    def get_cumulative_latencies(self) -> CumulativeLatencies:
        """Get cumulative latencies."""
        return self.stats.to_cumulative_latencies()

    def reset_stats(self):
        """
        Reset all statistics - ä½¿ç”¨epochæœºåˆ¶é¿å…ç«æ€æ¡ä»¶.

        ç­–ç•¥:
        1. é€’å¢reset_stats_flagï¼ˆæ–°çš„epochï¼‰
        2. Agentè¿›ç¨‹çœ‹åˆ°æ–°epochåï¼Œé‡ç½®æœ¬åœ°ç»Ÿè®¡å¹¶åœ¨ä¸‹æ¬¡æ±‡æŠ¥æ—¶å¸¦ä¸Šæ–°epoch
        3. ç»Ÿè®¡æ”¶é›†çº¿ç¨‹ä¸¢å¼ƒæ—§epochçš„æ•°æ®
        4. ä¸»è¿›ç¨‹æ™ºèƒ½ç­‰å¾…ç¡®ä¿æ‰€æœ‰Agentè¿›å…¥æ–°epoch
        5. åªæ¸…ç©ºæ—§epochçš„ç»Ÿè®¡æ•°æ®
        6. é‡ç½®ä¸»ç»Ÿè®¡å¯¹è±¡
        """
        logger.info("Resetting stats (using epoch mechanism)...")

        # 1. é€’å¢epochï¼ˆå‘Šè¯‰æ‰€æœ‰Agentè¦é‡ç½®äº†ï¼‰
        old_epoch = self.reset_stats_flag.value
        new_epoch = old_epoch + 1
        self.reset_stats_flag.value = new_epoch
        logger.info(f"Stats reset: epoch {old_epoch} -> {new_epoch}")

        # 2. æ™ºèƒ½ç­‰å¾…æ‰€æœ‰Agentè¿›å…¥æ–°epoch
        #    æ£€æŸ¥é˜Ÿåˆ—ä¸­æ”¶åˆ°çš„ç»Ÿè®¡æ•°æ®çš„epochï¼Œç¡®ä¿æ‰€æœ‰Agentå·²å“åº”
        if self.agent_processes:
            num_agents = len(self.agent_processes)
            agents_entered_new_epoch = set()
            # åŠ¨æ€è°ƒæ•´ç­‰å¾…æ—¶é—´ï¼šåŸºæœ¬2ç§’ + æ¯ä¸ªAgent 0.2ç§’ï¼ˆå…è®¸æ…¢é€Ÿconsumerå“åº”ï¼‰
            # ä¾‹å¦‚ï¼š31ä¸ªAgent â†’ 2 + 31*0.2 = 8.2ç§’
            max_wait_time = max(10.0, 2.0 + num_agents * 1)
            start_wait = time.time()

            logger.info(f"Waiting for {num_agents} agents to enter new epoch {new_epoch} (timeout: {max_wait_time:.1f}s)...")

            while len(agents_entered_new_epoch) < num_agents:
                if time.time() - start_wait > max_wait_time:
                    logger.warning(
                        f"Timeout waiting for agents to enter new epoch. "
                        f"Only {len(agents_entered_new_epoch)}/{num_agents} agents confirmed."
                    )
                    break

                try:
                    # éé˜»å¡æ£€æŸ¥é˜Ÿåˆ—
                    stats_dict = self.stats_queue.get(timeout=0.1)
                    agent_id = stats_dict.get('agent_id')
                    stats_epoch = stats_dict.get('epoch', 0)

                    if stats_epoch >= new_epoch:
                        agents_entered_new_epoch.add(agent_id)
                        logger.debug(f"Agent {agent_id} entered epoch {stats_epoch} ({len(agents_entered_new_epoch)}/{num_agents})")
                    # æ—§epochçš„æ•°æ®ç›´æ¥ä¸¢å¼ƒ
                except:
                    # é˜Ÿåˆ—ç©ºæˆ–è¶…æ—¶ï¼Œç»§ç»­ç­‰å¾…
                    pass

            if len(agents_entered_new_epoch) == num_agents:
                logger.info(f"All {num_agents} agents entered new epoch {new_epoch}")
            else:
                # æ‰¾å‡ºå“ªäº› agent æ²¡æœ‰ç¡®è®¤
                all_agent_ids = set(range(num_agents))
                missing_agents = all_agent_ids - agents_entered_new_epoch
                logger.warning(
                    f"Only {len(agents_entered_new_epoch)}/{num_agents} agents confirmed new epoch. "
                    f"Missing agents: {sorted(missing_agents)}"
                )

        # 3. æ¸…ç©ºqueueä¸­å‰©ä½™çš„æ—§epochæ•°æ®ï¼ˆåªæ¸…ç†æ—§epochï¼Œä¿ç•™æ–°epochæ•°æ®ï¼‰
        drained_old = 0
        drained_new = 0
        saved_new_epoch_stats = []

        try:
            while not self.stats_queue.empty():
                try:
                    stats_dict = self.stats_queue.get_nowait()
                    stats_epoch = stats_dict.get('epoch', 0)

                    if stats_epoch < new_epoch:
                        # æ—§epochæ•°æ®ï¼Œä¸¢å¼ƒ
                        drained_old += 1
                    else:
                        # æ–°epochæ•°æ®ï¼Œä¿å­˜å¹¶é‡æ–°æ”¾å›é˜Ÿåˆ—
                        saved_new_epoch_stats.append(stats_dict)
                        drained_new += 1
                except Exception as e:
                    logger.debug(f"Error draining queue: {e}")
                    break
        except Exception as e:
            logger.warning(f"Error while draining stats queue: {e}")

        # å°†æ–°epochçš„ç»Ÿè®¡æ•°æ®æ”¾å›é˜Ÿåˆ—
        for stats_dict in saved_new_epoch_stats:
            try:
                self.stats_queue.put_nowait(stats_dict)
            except Exception as e:
                logger.warning(f"Failed to restore new epoch stats to queue: {e}")

        if drained_old > 0 or drained_new > 0:
            logger.info(f"Drained {drained_old} old epoch entries, preserved {drained_new} new epoch entries")

        # 4. é‡ç½®ä¸»ç»Ÿè®¡å¯¹è±¡
        self.stats.reset()
        logger.info("Stats reset completed")

    def stop_all(self):
        """åœæ­¢æ‰€æœ‰Agentè¿›ç¨‹å’ŒConsumers - ä¼˜é›…å…³é—­"""
        self.test_completed.set()

        # 1. åœæ­¢Agentè¿›ç¨‹
        if self.agent_processes:
            logger.info(f"Stopping {len(self.agent_processes)} Agent processes...")
            self.stop_agents.set()

            # å¹¶å‘ç­‰å¾…æ‰€æœ‰è¿›ç¨‹åŒæ—¶é€€å‡ºï¼ˆç»™è¶³å¤Ÿæ—¶é—´flushæ•°æ®ï¼Œæœ€å¤š10ç§’ï¼‰
            # ä½¿ç”¨ç›¸åŒçš„timeoutç¡®ä¿æ‰€æœ‰è¿›ç¨‹å‡ ä¹åŒæ—¶åœæ­¢ï¼Œæœ€å°åŒ–è®¡æ•°å™¨å·®å¼‚
            timeout = 10.0
            start_time = time.time()

            # å¹¶å‘ç­‰å¾…æ‰€æœ‰è¿›ç¨‹
            for process in self.agent_processes:
                process.join(timeout=0.01)  # å…ˆå¿«é€Ÿæ£€æŸ¥ä¸€æ¬¡ï¼Œä¸é˜»å¡

            # ç»Ÿä¸€ç­‰å¾…å‰©ä½™æ—¶é—´
            elapsed = time.time() - start_time
            remaining = max(0, timeout - elapsed)
            if remaining > 0:
                time.sleep(remaining)

            # æ£€æŸ¥å“ªäº›è¿›ç¨‹è¿˜æ´»ç€
            all_stopped = True
            for process in self.agent_processes:
                if process.is_alive():
                    all_stopped = False
                    break

            if all_stopped:
                logger.info("All Agent processes exited gracefully")
            else:
                # è¿˜æœ‰è¿›ç¨‹åœ¨è¿è¡Œï¼Œå†ç»™3ç§’å®½é™æœŸ
                alive_processes = [p for p in self.agent_processes if p.is_alive()]
                logger.warning(f"{len(alive_processes)} Agent processes still running, giving 3s grace period...")
                time.sleep(3.0)

                # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰è¿›ç¨‹
                alive_processes = [p for p in self.agent_processes if p.is_alive()]
                if alive_processes:
                    logger.warning(f"Force terminating {len(alive_processes)} Agent processes that didn't exit")
                    for process in alive_processes:
                        logger.warning(f"Terminating Agent process: {process.name} (PID: {process.pid})")
                        try:
                            process.terminate()
                        except:
                            pass

                    # å†ç­‰1ç§’è®©terminateç”Ÿæ•ˆ
                    time.sleep(1.0)

                    # å¦‚æœè¿˜æ´»ç€ï¼Œå¼ºåˆ¶kill
                    still_alive = [p for p in alive_processes if p.is_alive()]
                    if still_alive:
                        logger.error(f"Forcefully killing {len(still_alive)} unresponsive processes")
                        for process in still_alive:
                            try:
                                process.kill()
                            except:
                                pass

            self.agent_processes.clear()
            logger.info("All Agent processes stopped")

        # 2. åœæ­¢ç»Ÿè®¡æ”¶é›†çº¿ç¨‹
        if self.stats_collector_running:
            self.stats_collector_running = False
            if self.stats_collector_thread and self.stats_collector_thread.is_alive():
                self.stats_collector_thread.join(timeout=2.0)
            logger.info("Stats collector stopped")

        # 3. æ¸…ç©ºç»Ÿè®¡é˜Ÿåˆ—å‰©ä½™æ•°æ®
        drained_count = 0
        try:
            while not self.stats_queue.empty():
                self.stats_queue.get_nowait()
                drained_count += 1
        except Exception as e:
            logger.warning(f"Error while draining stats queue during stop_all: {e}")

        if drained_count > 0:
            logger.info(f"Drained {drained_count} entries from stats queue during cleanup")

        # 4. å…³é—­V1 Consumersï¼ˆå¦‚æœæœ‰ï¼‰
        if self.consumers:
            logger.info("Closing V1 consumers...")
            for consumer in self.consumers:
                try:
                    consumer.close()
                except Exception as e:
                    logger.error(f"Error closing consumer: {e}")
            self.consumers.clear()

        # V2æ¶æ„ï¼šConsumeråœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ï¼Œå·²é€šè¿‡stop_agents.set()åœæ­¢

        self.producers.clear()
        self.consumer_metadata.clear()

    def id(self) -> str:
        """Get worker ID."""
        return "local-worker"

    def close(self):
        """Close worker and cleanup."""
        self.stop_all()

        if self.benchmark_driver is not None:
            try:
                self.benchmark_driver.close()
            except Exception as e:
                logger.error(f"Error closing driver: {e}")

    # ConsumerCallback interface implementation (V1å…¼å®¹æ€§ä¿ç•™)
    def message_received(self, payload: bytes, publish_timestamp_ms: int):
        """
        Callback when message is received (ConsumerCallback interface).

        V1æ¶æ„ï¼šåœ¨ä¸»è¿›ç¨‹ä¸­çš„Consumerä½¿ç”¨æ­¤callback
        V2æ¶æ„ï¼šConsumeråœ¨ç‹¬ç«‹è¿›ç¨‹ä¸­ï¼Œä¸ä½¿ç”¨æ­¤callbackï¼ˆç›´æ¥åœ¨è¿›ç¨‹å†…è®¡ç®—E2Eå»¶è¿Ÿï¼‰

        :param payload: Message payload
        :param publish_timestamp_ms: Publish timestamp in milliseconds (from epoch)
        """
        import time
        # IMPORTANT: Use milliseconds (same as Java) to match Kafka timestamp
        receive_timestamp_ms = int(time.time() * 1000)  # Convert to milliseconds from epoch
        end_to_end_latency_ms = receive_timestamp_ms - publish_timestamp_ms if publish_timestamp_ms > 0 else 0
        # Record in milliseconds for stats
        self.stats.record_message_received(len(payload), end_to_end_latency_ms)
        logger.debug(f"[V1] Message received callback: payload_size={len(payload)}, e2e_latency_ms={end_to_end_latency_ms}, total_received={self.stats.total_messages_received.sum()}")
